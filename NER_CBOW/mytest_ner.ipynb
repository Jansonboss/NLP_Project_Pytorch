{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition (NER)\n",
    "\n",
    "Named Entity Recognition (NER) is an important  task in natural language processing. In this assignment you will implement a neural network model for NER.  In particular you will implement an approach called Sliding Window Neural Network. The dataset is composed of sentences. The dataframe already has each words parsed in one column and the corresponding label (entity) in the second column. We will build a \"window\" model, the idea on the window model is to use 5-word window to predict the name entity of the middle word. Here is the first observation in our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ner import *\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/Genia4ERtask1.iob2\", sep=\"\\t\", header=None, names=[\"word\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         word      label\n",
       "0        IL-2      B-DNA\n",
       "1        gene      I-DNA\n",
       "2  expression          O\n",
       "3         and          O\n",
       "4    NF-kappa  B-protein\n",
       "5           B  I-protein\n",
       "6  activation          O\n",
       "7     through          O\n",
       "8        CD28  B-protein\n",
       "9    requires          O"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>IL-2</td>\n      <td>B-DNA</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>gene</td>\n      <td>I-DNA</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>expression</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>and</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NF-kappa</td>\n      <td>B-protein</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>B</td>\n      <td>I-protein</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>activation</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>through</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>CD28</td>\n      <td>B-protein</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>requires</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_data = pd.read_csv(\"data/tiny.ner.train\", sep=\"\\t\", header=None, names=[\"word\", \"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second observation is the 5 words starting with 'gene' and the label is the entity for the word 'and'. We have 5 features (categorical variables) which are words. We will use a word embedding to represent each value of the categorical features. For each observation, we concatenate the values of the 5 word embeddings for that observation. The vector of concatenated embeddings is feeded to a linear layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "394040"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "N = int(data.shape[0]*0.8)\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data.iloc[:N,].copy()\n",
    "valid_df = data.iloc[N:,].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((394040, 2), (98511, 2))"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "train_df.shape, valid_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word and label to index mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab2index = label_encoding(train_df[\"word\"].values)\n",
    "label2index = label_encoding(train_df[\"label\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_vocab2index = label_encoding(tiny_data[\"word\"].values)\n",
    "tiny_label2index = label_encoding(tiny_data[\"label\"].values)\n",
    "tiny_data_enc = dataset_encoding(tiny_data, tiny_vocab2index, tiny_label2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = np.array([17, 53, 31, 25, 44, 41, 32,  0, 11,  1])\n",
    "assert(np.array_equal(tiny_data_enc.iloc[30:40].word.values, actual))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_ds = NERDataset(tiny_data_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "len(tiny_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    word  label\n",
       "0     11      0\n",
       "1     30      3\n",
       "2     26      6\n",
       "3     18      6\n",
       "4     13      2\n",
       "5      7      5\n",
       "6     17      6\n",
       "7     60      6\n",
       "8      8      2\n",
       "9     52      6\n",
       "10    49      6\n",
       "11    42      6\n",
       "12    44      6\n",
       "13    20      6\n",
       "14     5      2\n",
       "15     3      6\n",
       "16     6      6\n",
       "17    41      6\n",
       "18    59      6\n",
       "19     8      2"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>11</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>30</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>26</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>18</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>13</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>7</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>17</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>60</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>52</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>49</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>42</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>44</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>20</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>5</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>3</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>6</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>41</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>59</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>8</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "tiny_data_enc[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(len(tiny_data_enc)):\n",
    "    if i+2<= len(tiny_data_enc):\n",
    "        data.append(tiny_data_enc[i:i+5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "len(tiny_ds[:][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([11, 30, 26, 18, 13]), 6)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "x, y = tiny_ds[0]\n",
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = tiny_ds[0]\n",
    "assert(np.array_equal(x, np.array([11, 30, 26, 18, 13])))\n",
    "assert(y == 6)\n",
    "assert(len(tiny_ds) == 93)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding datasets\n",
    "train_df_enc = dataset_encoding(train_df, vocab2index, label2index)\n",
    "valid_df_enc = dataset_encoding(valid_df, vocab2index, label2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating datasets\n",
    "train_ds =  NERDataset(train_df_enc)\n",
    "valid_ds = NERDataset(valid_df_enc)\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 10000\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ner import *\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train loss  0.758 val loss 0.404 and accuracy 0.877\n",
      "train loss  0.318 val loss 0.325 and accuracy 0.899\n",
      "train loss  0.251 val loss 0.301 and accuracy 0.906\n",
      "train loss  0.217 val loss 0.308 and accuracy 0.905\n",
      "train loss  0.195 val loss 0.286 and accuracy 0.911\n",
      "train loss  0.181 val loss 0.297 and accuracy 0.908\n",
      "train loss  0.170 val loss 0.285 and accuracy 0.912\n",
      "train loss  0.162 val loss 0.296 and accuracy 0.910\n",
      "train loss  0.156 val loss 0.311 and accuracy 0.909\n",
      "train loss  0.151 val loss 0.310 and accuracy 0.908\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab2index)+1\n",
    "n_class = len(label2index)\n",
    "emb_size = 100\n",
    "\n",
    "\n",
    "model = NERModel(vocab_size, n_class, emb_size)\n",
    "optimizer = get_optimizer(model, lr = 0.01, wd = 1e-5)\n",
    "train_model(model, optimizer, train_dl, valid_dl, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train loss  1.629 val loss 1.652 and accuracy 0.895\n",
      "train loss  1.626 val loss 1.651 and accuracy 0.897\n",
      "train loss  1.625 val loss 1.650 and accuracy 0.897\n",
      "train loss  1.622 val loss 1.645 and accuracy 0.903\n",
      "train loss  1.619 val loss 1.643 and accuracy 0.905\n",
      "train loss  1.616 val loss 1.641 and accuracy 0.907\n",
      "train loss  1.614 val loss 1.640 and accuracy 0.908\n",
      "train loss  1.612 val loss 1.639 and accuracy 0.909\n",
      "train loss  1.610 val loss 1.639 and accuracy 0.909\n",
      "train loss  1.609 val loss 1.638 and accuracy 0.909\n"
     ]
    }
   ],
   "source": [
    "optimizer = get_optimizer(model, lr = 0.001, wd = 1e-5)\n",
    "train_model(model, optimizer, train_dl, valid_dl, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loss, valid_acc = valid_metrics(model, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1.6383890185784586, 0.9093668470260997)"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "valid_loss, valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AssertionError",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-845903494f73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loss\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.02\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert(np.abs(valid_loss - 0.3) < 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(np.abs(valid_acc - 0.9) < 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = nn.Linear(10, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([3, 10])"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "a1.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd0e134e05457d34029b6460cd73bbf1ed73f339b5b6d98c95be70b69eba114fe95",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}